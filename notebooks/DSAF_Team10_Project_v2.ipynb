{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ytbjNyfmew7l"
   },
   "source": [
    "# **Predicting Bank Failures Using Machine Learning**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PijJ4Ptzez9Q"
   },
   "source": [
    "***Model Development and Operational Details***\n",
    "\n",
    "In this workbook, we perform in depth exploratory data analysis, data wrangling, and finally apply a logistic regression analysis to categorize banks as risky or healthy, in line with the FDIC's collected data. As discussed above, we use the Homeland Infrastructure Foundation's 2016 FDIC Insured Banks Data Set.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-YCndrOmspsv"
   },
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-YCndrOmspsv"
   },
   "source": [
    "#### Local imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-28T00:56:07.589493Z",
     "iopub.status.busy": "2023-04-28T00:56:07.589012Z",
     "iopub.status.idle": "2023-04-28T00:56:07.605346Z",
     "shell.execute_reply": "2023-04-28T00:56:07.602521Z",
     "shell.execute_reply.started": "2023-04-28T00:56:07.589403Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "import os\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-YCndrOmspsv"
   },
   "source": [
    "#### Third party imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-28T00:56:07.609167Z",
     "iopub.status.busy": "2023-04-28T00:56:07.608467Z",
     "iopub.status.idle": "2023-04-28T00:56:11.489515Z",
     "shell.execute_reply": "2023-04-28T00:56:11.488424Z",
     "shell.execute_reply.started": "2023-04-28T00:56:07.609114Z"
    },
    "id": "KpwjUM-YeFDr",
    "tags": []
   },
   "outputs": [],
   "source": [
    "##Install Packages\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.max_rows', 10)\n",
    "import numpy as np\n",
    "import sklearn.tree\n",
    "import sklearn.metrics\n",
    "import sklearn.model_selection\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import warnings\n",
    "from sklearn.metrics import roc_curve, roc_auc_score, auc, confusion_matrix\n",
    "import graphviz\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "from IPython.display import Image\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import plotly.figure_factory as ff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-YCndrOmspsv"
   },
   "source": [
    "#### Local application imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-28T00:56:11.493182Z",
     "iopub.status.busy": "2023-04-28T00:56:11.492359Z",
     "iopub.status.idle": "2023-04-28T00:56:12.375589Z",
     "shell.execute_reply": "2023-04-28T00:56:12.374243Z",
     "shell.execute_reply.started": "2023-04-28T00:56:11.493147Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from pkg_dir.config import *\n",
    "from pkg_dir.src.utils import *\n",
    "from pkg_dir.src.functions import *\n",
    "from pkg_dir.src.parameters import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FoALFdHYwgdl",
    "tags": []
   },
   "source": [
    "# Extraction and initial wrangling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aFxvNmBmwpQc",
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### Reading data from Google Drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 400
    },
    "id": "Ay7QpsKJtKYJ",
    "outputId": "c9d85bf2-72d9-40bc-ce4a-09a6bafccd5e",
    "tags": []
   },
   "outputs": [],
   "source": [
    "##Loading Data\n",
    "dfk = pd.read_csv('https://drive.google.com/uc?export=download&id=1vD7uj5Tpz2IvDj49YXR_4Xw2Pebhk_Ix')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dvbZzH2EzZFD",
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### Initial data wrangling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dvbZzH2EzZFD",
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "###### Setting index"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-27T18:30:27.661012Z",
     "iopub.status.busy": "2023-04-27T18:30:27.660598Z",
     "iopub.status.idle": "2023-04-27T18:30:27.737231Z",
     "shell.execute_reply": "2023-04-27T18:30:27.736292Z",
     "shell.execute_reply.started": "2023-04-27T18:30:27.660975Z"
    },
    "id": "moJoigxwziFp",
    "tags": []
   },
   "source": [
    "dfk.set_index('FID', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K_M3CGoN5gCA",
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "###### Target variable - label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 300
    },
    "id": "3HskvuqdA3Tx",
    "outputId": "7a63b4ad-97e4-4aa8-9ae6-a5b3b57c9ae5",
    "tags": []
   },
   "outputs": [],
   "source": [
    "dfk['SCORE_T'] = (dfk['SCORE'] < 100)*1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K_M3CGoN5gCA",
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "###### Adding relevant variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dfk['DEP_RATIOS'] = dfk['DEPSUMBR']/dfk['DEPDOM']\n",
    "dfk['DEP_RATIOS'][dfk['DEPDOM']==0] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aFxvNmBmwpQc",
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "###### Data information"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "ADDRESBR: Address of the bank. (String)\n",
    "BRNUM: Bank number. (Integer)\n",
    "BRSERTYP: Type of bank. (String)\n",
    "CBSABR: Core-Based Statistical Area code. (Integer)\n",
    "CBSANAMB: Core-Based Statistical Area name. (String)\n",
    "CITYBR: City of the bank. (String)\n",
    "CNTRYNAB: Country of the bank. (String)\n",
    "CNTYNAMB: County of the bank. (String)\n",
    "DEPSUMBR: Total deposits of the bank. (Integer)\n",
    "GEOCODE_CE: Geocode of the bank. (Integer)\n",
    "GEOCODE__1: Geocode of the bank. (Integer)\n",
    "NAMEBR: Name of the bank. (String)\n",
    "STALPBR: State abbreviation of the bank. (String)\n",
    "STCNTYBR: State and county of the bank. (String)\n",
    "STNAMEBR: State name of the bank. (String)\n",
    "UNINUMBR: Unique identifier for the bank. (Integer)\n",
    "ZIPBR: Zip code of the bank. (Integer)\n",
    "CERT: Certificate number of the bank. (Integer)\n",
    "ADDRESS: Address of the bank. (String)\n",
    "ASSET: Asset size of the bank. (Integer)\n",
    "BKCLASS: Bank classification. (String)\n",
    "CITY: City of the bank. (String)\n",
    "CITY: City of the bank. (String)\n",
    "CNTRYNA: Country of the bank. (String)\n",
    "DENOVO: Denovo status of the bank. (String)\n",
    "DEPDOM: Domestic deposits of the bank. (Integer)\n",
    "NAMEFULL: Full name of the bank. (String)\n",
    "NAMEHCR: Holding company name of the bank. (String)\n",
    "REGAGNT: Regulatory agency of the bank. (String)\n",
    "REPDTE: Report date of the bank. (Date)\n",
    "STALP: State abbreviation of the bank. (String)\n",
    "STCNTY: State and county of the bank. (String)\n",
    "STNAME: State name of the bank. (String)\n",
    "ZIP: Zip code of the bank. (Integer)\n",
    "BKMO: Bank month of the bank. (Integer)\n",
    "LOC_NAME: Location name of the bank. (String)\n",
    "STATUS: Status of the bank. (String)\n",
    "SCORE: Risk score of the bank. (Integer)\n",
    "x: Longitude of the bank. (Float)\n",
    "GeocodeSou: Geocode source of the bank. (String)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dfk.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aFxvNmBmwpQc",
    "tags": []
   },
   "source": [
    "###### Generating data schema"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-27T18:31:24.011765Z",
     "iopub.status.busy": "2023-04-27T18:31:24.010991Z",
     "iopub.status.idle": "2023-04-27T18:31:24.088553Z",
     "shell.execute_reply": "2023-04-27T18:31:24.087669Z",
     "shell.execute_reply.started": "2023-04-27T18:31:24.011731Z"
    },
    "tags": []
   },
   "source": [
    "data_dicts_loc = '../pkg_dir/src/parameters/'\n",
    "data_dict_filename = 'data_schema'\n",
    "generate_data_dictionary(dfk.columns, data_dicts_loc, data_dict_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BEMI3tCqzZCQ"
   },
   "source": [
    "###### Splitting data in test and train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Qrh7A90czj1r",
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    dfk.loc[:, dfk.columns != 'SCORE_T'],\n",
    "    dfk['SCORE_T'], \n",
    "    test_size=0.3,\n",
    "    random_state=9,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Merging data to solve pipeline problem\n",
    "dfk_train = pd.merge(\n",
    "    left=X_train,\n",
    "    right=y_train,\n",
    "    left_index=True,\n",
    "    right_index=True,\n",
    ")\n",
    "\n",
    "dfk_train.to_csv('../pkg_dir/data/dataset/banks_data_/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Merging data to solve pipeline problem\n",
    "dfk_test = pd.merge(\n",
    "    left=X_test,\n",
    "    right=y_test,\n",
    "    left_index=True,\n",
    "    right_index=True,\n",
    ")\n",
    "\n",
    "dfk_test.to_csv('../pkg_dir/data/dataset/banks_data_/test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aFxvNmBmwpQc",
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### Applying extract pipeline function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "extract_pipeline_func()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aFxvNmBmwpQc",
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### Evaluating saved pickles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset_objs_path = '../pkg_dir/data/pickles/pipeline/extract/'\n",
    "objects = os.listdir(dataset_objs_path)\n",
    "obj = objects[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open(dataset_objs_path + obj, 'rb') as obj_content:\n",
    "    dfx = pickle.load(obj_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l27qWIYj5f_J",
    "tags": []
   },
   "source": [
    "# Data transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-28T00:56:14.998669Z",
     "iopub.status.busy": "2023-04-28T00:56:14.998194Z",
     "iopub.status.idle": "2023-04-28T00:56:16.218025Z",
     "shell.execute_reply": "2023-04-28T00:56:16.216891Z",
     "shell.execute_reply.started": "2023-04-28T00:56:14.998629Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "transform_pipeline_func()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aFxvNmBmwpQc",
    "tags": []
   },
   "source": [
    "#### Evaluating saved pickles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset_objs_path = '../pkg_dir/data/pickles/pipeline/trans/'\n",
    "objects = os.listdir(dataset_objs_path)\n",
    "obj = objects[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open(dataset_objs_path + obj, 'rb') as obj_content:\n",
    "    dfx = pickle.load(obj_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0swVsM2B5gEo",
    "tags": []
   },
   "source": [
    "# Data exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K_M3CGoN5gCA",
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### `SCORE_T`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "px.histogram(\n",
    "    x=dfk['SCORE'],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l27qWIYj5f_J",
    "tags": []
   },
   "source": [
    "# Feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-28T00:56:17.159355Z",
     "iopub.status.busy": "2023-04-28T00:56:17.158926Z",
     "iopub.status.idle": "2023-04-28T00:56:18.822969Z",
     "shell.execute_reply": "2023-04-28T00:56:18.821983Z",
     "shell.execute_reply.started": "2023-04-28T00:56:17.159321Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "feateng_pipeline_func()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aFxvNmBmwpQc",
    "tags": []
   },
   "source": [
    "#### Evaluating saved pickles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset_objs_path = '../pkg_dir/data/pickles/pipeline/feateng/'\n",
    "objects = os.listdir(dataset_objs_path)\n",
    "obj = objects[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open(dataset_objs_path + obj, 'rb') as obj_content:\n",
    "    dfx = pickle.load(obj_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K_M3CGoN5gCA"
   },
   "source": [
    "# Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-28T00:56:19.343739Z",
     "iopub.status.busy": "2023-04-28T00:56:19.342978Z",
     "iopub.status.idle": "2023-04-28T00:59:59.292496Z",
     "shell.execute_reply": "2023-04-28T00:59:59.290356Z",
     "shell.execute_reply.started": "2023-04-28T00:56:19.343707Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model in training:  random_forest\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rp_mbp/Documents/educacion/maestria/berkeley_mba_meng/academics/2023_spring/data_science_applied_to_finance_and_accounting/UCB_gclass_ds_for_finance_and_accounting/.venv/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/rp_mbp/Documents/educacion/maestria/berkeley_mba_meng/academics/2023_spring/data_science_applied_to_finance_and_accounting/UCB_gclass_ds_for_finance_and_accounting/.venv/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/rp_mbp/Documents/educacion/maestria/berkeley_mba_meng/academics/2023_spring/data_science_applied_to_finance_and_accounting/UCB_gclass_ds_for_finance_and_accounting/.venv/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/rp_mbp/Documents/educacion/maestria/berkeley_mba_meng/academics/2023_spring/data_science_applied_to_finance_and_accounting/UCB_gclass_ds_for_finance_and_accounting/.venv/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/rp_mbp/Documents/educacion/maestria/berkeley_mba_meng/academics/2023_spring/data_science_applied_to_finance_and_accounting/UCB_gclass_ds_for_finance_and_accounting/.venv/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/rp_mbp/Documents/educacion/maestria/berkeley_mba_meng/academics/2023_spring/data_science_applied_to_finance_and_accounting/UCB_gclass_ds_for_finance_and_accounting/.venv/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/rp_mbp/Documents/educacion/maestria/berkeley_mba_meng/academics/2023_spring/data_science_applied_to_finance_and_accounting/UCB_gclass_ds_for_finance_and_accounting/.venv/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/rp_mbp/Documents/educacion/maestria/berkeley_mba_meng/academics/2023_spring/data_science_applied_to_finance_and_accounting/UCB_gclass_ds_for_finance_and_accounting/.venv/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/rp_mbp/Documents/educacion/maestria/berkeley_mba_meng/academics/2023_spring/data_science_applied_to_finance_and_accounting/UCB_gclass_ds_for_finance_and_accounting/.venv/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/rp_mbp/Documents/educacion/maestria/berkeley_mba_meng/academics/2023_spring/data_science_applied_to_finance_and_accounting/UCB_gclass_ds_for_finance_and_accounting/.venv/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model in training:  decision_tree\n",
      "Model in training:  logistic_regression\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rp_mbp/Documents/educacion/maestria/berkeley_mba_meng/academics/2023_spring/data_science_applied_to_finance_and_accounting/UCB_gclass_ds_for_finance_and_accounting/.venv/lib/python3.9/site-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/rp_mbp/Documents/educacion/maestria/berkeley_mba_meng/academics/2023_spring/data_science_applied_to_finance_and_accounting/UCB_gclass_ds_for_finance_and_accounting/.venv/lib/python3.9/site-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/rp_mbp/Documents/educacion/maestria/berkeley_mba_meng/academics/2023_spring/data_science_applied_to_finance_and_accounting/UCB_gclass_ds_for_finance_and_accounting/.venv/lib/python3.9/site-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/rp_mbp/Documents/educacion/maestria/berkeley_mba_meng/academics/2023_spring/data_science_applied_to_finance_and_accounting/UCB_gclass_ds_for_finance_and_accounting/.venv/lib/python3.9/site-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/rp_mbp/Documents/educacion/maestria/berkeley_mba_meng/academics/2023_spring/data_science_applied_to_finance_and_accounting/UCB_gclass_ds_for_finance_and_accounting/.venv/lib/python3.9/site-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/rp_mbp/Documents/educacion/maestria/berkeley_mba_meng/academics/2023_spring/data_science_applied_to_finance_and_accounting/UCB_gclass_ds_for_finance_and_accounting/.venv/lib/python3.9/site-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/rp_mbp/Documents/educacion/maestria/berkeley_mba_meng/academics/2023_spring/data_science_applied_to_finance_and_accounting/UCB_gclass_ds_for_finance_and_accounting/.venv/lib/python3.9/site-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/rp_mbp/Documents/educacion/maestria/berkeley_mba_meng/academics/2023_spring/data_science_applied_to_finance_and_accounting/UCB_gclass_ds_for_finance_and_accounting/.venv/lib/python3.9/site-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/rp_mbp/Documents/educacion/maestria/berkeley_mba_meng/academics/2023_spring/data_science_applied_to_finance_and_accounting/UCB_gclass_ds_for_finance_and_accounting/.venv/lib/python3.9/site-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/rp_mbp/Documents/educacion/maestria/berkeley_mba_meng/academics/2023_spring/data_science_applied_to_finance_and_accounting/UCB_gclass_ds_for_finance_and_accounting/.venv/lib/python3.9/site-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/rp_mbp/Documents/educacion/maestria/berkeley_mba_meng/academics/2023_spring/data_science_applied_to_finance_and_accounting/UCB_gclass_ds_for_finance_and_accounting/.venv/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:378: FitFailedWarning: \n",
      "30 fits failed out of a total of 40.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/rp_mbp/Documents/educacion/maestria/berkeley_mba_meng/academics/2023_spring/data_science_applied_to_finance_and_accounting/UCB_gclass_ds_for_finance_and_accounting/.venv/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/rp_mbp/Documents/educacion/maestria/berkeley_mba_meng/academics/2023_spring/data_science_applied_to_finance_and_accounting/UCB_gclass_ds_for_finance_and_accounting/.venv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/Users/rp_mbp/Documents/educacion/maestria/berkeley_mba_meng/academics/2023_spring/data_science_applied_to_finance_and_accounting/UCB_gclass_ds_for_finance_and_accounting/.venv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/rp_mbp/Documents/educacion/maestria/berkeley_mba_meng/academics/2023_spring/data_science_applied_to_finance_and_accounting/UCB_gclass_ds_for_finance_and_accounting/.venv/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/rp_mbp/Documents/educacion/maestria/berkeley_mba_meng/academics/2023_spring/data_science_applied_to_finance_and_accounting/UCB_gclass_ds_for_finance_and_accounting/.venv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/Users/rp_mbp/Documents/educacion/maestria/berkeley_mba_meng/academics/2023_spring/data_science_applied_to_finance_and_accounting/UCB_gclass_ds_for_finance_and_accounting/.venv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "20 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/rp_mbp/Documents/educacion/maestria/berkeley_mba_meng/academics/2023_spring/data_science_applied_to_finance_and_accounting/UCB_gclass_ds_for_finance_and_accounting/.venv/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/rp_mbp/Documents/educacion/maestria/berkeley_mba_meng/academics/2023_spring/data_science_applied_to_finance_and_accounting/UCB_gclass_ds_for_finance_and_accounting/.venv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 1160, in fit\n",
      "    self._validate_params()\n",
      "  File \"/Users/rp_mbp/Documents/educacion/maestria/berkeley_mba_meng/academics/2023_spring/data_science_applied_to_finance_and_accounting/UCB_gclass_ds_for_finance_and_accounting/.venv/lib/python3.9/site-packages/sklearn/base.py\", line 581, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/Users/rp_mbp/Documents/educacion/maestria/berkeley_mba_meng/academics/2023_spring/data_science_applied_to_finance_and_accounting/UCB_gclass_ds_for_finance_and_accounting/.venv/lib/python3.9/site-packages/sklearn/utils/_param_validation.py\", line 97, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'class_weight' parameter of LogisticRegression must be an instance of 'dict', a str among {'balanced'} or None. Got 'Balanced' instead.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/Users/rp_mbp/Documents/educacion/maestria/berkeley_mba_meng/academics/2023_spring/data_science_applied_to_finance_and_accounting/UCB_gclass_ds_for_finance_and_accounting/.venv/lib/python3.9/site-packages/sklearn/model_selection/_search.py:952: UserWarning: One or more of the test scores are non-finite: [0.93190687        nan 0.93439532        nan        nan        nan\n",
      "        nan        nan]\n",
      "  warnings.warn(\n",
      "/Users/rp_mbp/Documents/educacion/maestria/berkeley_mba_meng/academics/2023_spring/data_science_applied_to_finance_and_accounting/UCB_gclass_ds_for_finance_and_accounting/.venv/lib/python3.9/site-packages/sklearn/model_selection/_search.py:952: UserWarning: One or more of the train scores are non-finite: [1.                nan 0.94096993        nan        nan        nan\n",
      "        nan        nan]\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "modtrain_pipeline_func()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aFxvNmBmwpQc",
    "tags": []
   },
   "source": [
    "#### Evaluating saved pickles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset_objs_path = '../pkg_dir/data/pickles/pipeline/modtrain/'\n",
    "objects = os.listdir(dataset_objs_path)\n",
    "obj = objects[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open(dataset_objs_path + obj, 'rb') as obj_content:\n",
    "    dfx = pickle.load(obj_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K_M3CGoN5gCA"
   },
   "source": [
    "# Models evaluation and selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-28T01:00:04.546744Z",
     "iopub.status.busy": "2023-04-28T01:00:04.546303Z",
     "iopub.status.idle": "2023-04-28T01:00:04.720115Z",
     "shell.execute_reply": "2023-04-28T01:00:04.718680Z",
     "shell.execute_reply.started": "2023-04-28T01:00:04.546710Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "X has 38812 features, but RandomForestClassifier is expecting 128797 features as input.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [8]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mmodevalsel_pipeline_func\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/educacion/maestria/berkeley_mba_meng/academics/2023_spring/data_science_applied_to_finance_and_accounting/UCB_gclass_ds_for_finance_and_accounting/pkg_dir/src/functions/pipeline/modevalsel_funcs.py:145\u001b[0m, in \u001b[0;36mmodevalsel_pipeline_func\u001b[0;34m()\u001b[0m\n\u001b[1;32m    142\u001b[0m modtrain_res \u001b[38;5;241m=\u001b[39m load_trained_models()\n\u001b[1;32m    144\u001b[0m \u001b[38;5;66;03m## Add the trained models' predictions for the validation labels\u001b[39;00m\n\u001b[0;32m--> 145\u001b[0m dataset_dict \u001b[38;5;241m=\u001b[39m \u001b[43madd_validation_predictions_per_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodtrain_res\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    147\u001b[0m \u001b[38;5;66;03m## Generate a summary performance metrics table for every model with the validation dataset\u001b[39;00m\n\u001b[1;32m    148\u001b[0m metrics_table \u001b[38;5;241m=\u001b[39m validation_models_performance_table(dataset_dict, modtrain_res, model_eval_metrics)\n",
      "File \u001b[0;32m~/Documents/educacion/maestria/berkeley_mba_meng/academics/2023_spring/data_science_applied_to_finance_and_accounting/UCB_gclass_ds_for_finance_and_accounting/pkg_dir/src/utils/ml_utils.py:445\u001b[0m, in \u001b[0;36madd_validation_predictions_per_model\u001b[0;34m(dataset_dict, trained_models_dict)\u001b[0m\n\u001b[1;32m    442\u001b[0m model_class_thresh \u001b[38;5;241m=\u001b[39m trained_models_dict[mdl][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mestimator_class_thresh\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m    444\u001b[0m \u001b[38;5;66;03m## Adding the prediction probabilities of the positive class to the validation results\u001b[39;00m\n\u001b[0;32m--> 445\u001b[0m y_val[model_alias \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_pos_prob\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict_proba\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_val\u001b[49m\u001b[43m)\u001b[49m[:, \u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m    447\u001b[0m \u001b[38;5;66;03m## Adding the prediction labels based on the classification threshold\u001b[39;00m\n\u001b[1;32m    448\u001b[0m y_val[model_alias \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_label\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mwhere(\n\u001b[1;32m    449\u001b[0m     y_val[model_alias \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_pos_prob\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m model_class_thresh,\n\u001b[1;32m    450\u001b[0m     \u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m    451\u001b[0m     \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m    452\u001b[0m )\n",
      "File \u001b[0;32m~/Documents/educacion/maestria/berkeley_mba_meng/academics/2023_spring/data_science_applied_to_finance_and_accounting/UCB_gclass_ds_for_finance_and_accounting/.venv/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:862\u001b[0m, in \u001b[0;36mForestClassifier.predict_proba\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    860\u001b[0m check_is_fitted(\u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m    861\u001b[0m \u001b[38;5;66;03m# Check data\u001b[39;00m\n\u001b[0;32m--> 862\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_X_predict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    864\u001b[0m \u001b[38;5;66;03m# Assign chunk of trees to jobs\u001b[39;00m\n\u001b[1;32m    865\u001b[0m n_jobs, _, _ \u001b[38;5;241m=\u001b[39m _partition_estimators(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_estimators, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_jobs)\n",
      "File \u001b[0;32m~/Documents/educacion/maestria/berkeley_mba_meng/academics/2023_spring/data_science_applied_to_finance_and_accounting/UCB_gclass_ds_for_finance_and_accounting/.venv/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:602\u001b[0m, in \u001b[0;36mBaseForest._validate_X_predict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    599\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    600\u001b[0m \u001b[38;5;124;03mValidate X whenever one tries to predict, apply, predict_proba.\"\"\"\u001b[39;00m\n\u001b[1;32m    601\u001b[0m check_is_fitted(\u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m--> 602\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mDTYPE\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    603\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m issparse(X) \u001b[38;5;129;01mand\u001b[39;00m (X\u001b[38;5;241m.\u001b[39mindices\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m!=\u001b[39m np\u001b[38;5;241m.\u001b[39mintc \u001b[38;5;129;01mor\u001b[39;00m X\u001b[38;5;241m.\u001b[39mindptr\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m!=\u001b[39m np\u001b[38;5;241m.\u001b[39mintc):\n\u001b[1;32m    604\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo support for np.int64 index based sparse matrices\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Documents/educacion/maestria/berkeley_mba_meng/academics/2023_spring/data_science_applied_to_finance_and_accounting/UCB_gclass_ds_for_finance_and_accounting/.venv/lib/python3.9/site-packages/sklearn/base.py:569\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[0;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[1;32m    566\u001b[0m     out \u001b[38;5;241m=\u001b[39m X, y\n\u001b[1;32m    568\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m check_params\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mensure_2d\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[0;32m--> 569\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_check_n_features\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    571\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "File \u001b[0;32m~/Documents/educacion/maestria/berkeley_mba_meng/academics/2023_spring/data_science_applied_to_finance_and_accounting/UCB_gclass_ds_for_finance_and_accounting/.venv/lib/python3.9/site-packages/sklearn/base.py:370\u001b[0m, in \u001b[0;36mBaseEstimator._check_n_features\u001b[0;34m(self, X, reset)\u001b[0m\n\u001b[1;32m    367\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m    369\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n_features \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_features_in_:\n\u001b[0;32m--> 370\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    371\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX has \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mn_features\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m features, but \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    372\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mis expecting \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_features_in_\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m features as input.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    373\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: X has 38812 features, but RandomForestClassifier is expecting 128797 features as input."
     ]
    }
   ],
   "source": [
    "modevalsel_pipeline_func()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BEMI3tCqzZCQ"
   },
   "source": [
    "### Models compilation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset_objs_path = '../pkg_dir/data/pickles/pipeline/modtrain/'\n",
    "objects = os.listdir(dataset_objs_path)\n",
    "obj = objects[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open(dataset_objs_path + obj, 'rb') as obj_content:\n",
    "    models = pickle.load(obj_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "lr = models['logistic_regression']['best_estimator']\n",
    "rf = models['random_forest']['best_estimator']\n",
    "dt = models['decision_tree']['best_estimator']\n",
    "# gb = models['gradient_boosting']['best_estimator']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BEMI3tCqzZCQ"
   },
   "source": [
    "### Datasets compilation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset_objs_path = '../pkg_dir/data/pickles/pipeline/modtrain/'\n",
    "objects = os.listdir(dataset_objs_path)\n",
    "\n",
    "with open(dataset_objs_path + objects[6], 'rb') as obj_content:\n",
    "    X_train = pickle.load(obj_content)\n",
    "    \n",
    "with open(dataset_objs_path + objects[4], 'rb') as obj_content:\n",
    "    y_train = pickle.load(obj_content)\n",
    "    \n",
    "with open(dataset_objs_path + objects[2], 'rb') as obj_content:\n",
    "    X_test = pickle.load(obj_content)\n",
    "    \n",
    "with open(dataset_objs_path + objects[3], 'rb') as obj_content:\n",
    "    y_test = pickle.load(obj_content)\n",
    "    \n",
    "with open(dataset_objs_path + objects[0], 'rb') as obj_content:\n",
    "    X_val = pickle.load(obj_content)\n",
    "    \n",
    "with open(dataset_objs_path + objects[1], 'rb') as obj_content:\n",
    "    y_val = pickle.load(obj_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SpuNAOcw5rqi"
   },
   "source": [
    "# Evaluating models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### General model metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dfx = pd.DataFrame(\n",
    "    # columns=['Logistic Regression', 'Decision Tree', 'Random Forest'],\n",
    "    index=[\n",
    "        'Training performance',\n",
    "        'Test performance',\n",
    "        'Training sensitivity',\n",
    "        'Training specificity',\n",
    "        'Test sensitivity',\n",
    "        'Test specificity',\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_name = 'random_forest'\n",
    "model_name = 'logistic_reg'\n",
    "model_name = 'decision_tree'\n",
    "\n",
    "model = rf\n",
    "model = lr\n",
    "model = dt\n",
    "\n",
    "predicted_train = model.predict(X_train)\n",
    "predicted_test = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cm_train = sklearn.metrics.confusion_matrix(y_train, predicted_train)\n",
    "cm_test = sklearn.metrics.confusion_matrix(y_test, predicted_test)\n",
    "\n",
    "def SensitivityAndSpecificity(cm):\n",
    "  # True positives are in the lower-right (row 1, column 1)\n",
    "  TP = cm[1, 1]\n",
    "  # True negatives are in the upper-left (row 0, column 0)\n",
    "  TN = cm[0, 0]\n",
    "  # False positives are in the upper-right (row 0, columns 1)\n",
    "  FP = cm[0, 1]\n",
    "  # False negatives are in the lower-left (row 1, column 0)\n",
    "  FN = cm[1, 0]\n",
    "  sensitivity = TP / (TP + FN)\n",
    "  specificity = TN / (TN + FP)\n",
    "  return {'Sensitivity': sensitivity, 'Specificity': specificity}\n",
    "\n",
    "dfx.loc['Training performance', model_name] = np.mean(predicted_train == y_train['label'])\n",
    "dfx.loc['Test performance', model_name] = np.mean(predicted_test == y_test['dummy_label'])\n",
    "dfx.loc['Training sensitivity', model_name] = SensitivityAndSpecificity(cm_train)['Sensitivity']\n",
    "dfx.loc['Training specificity', model_name] = SensitivityAndSpecificity(cm_train)['Specificity']\n",
    "dfx.loc['Test sensitivity', model_name] = SensitivityAndSpecificity(cm_test)['Sensitivity']\n",
    "dfx.loc['Test specificity', model_name] = SensitivityAndSpecificity(cm_test)['Specificity']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### CART regression feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=[12, 4])\n",
    "I = np.argsort(dtm.feature_importances_)\n",
    "plt.figure(figsize=[12, 4])\n",
    "plt.bar([features[i] for i in I], [dtm.feature_importances_[i] for i in I])\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# model_name = 'logistic_reg'\n",
    "# model_name = 'random_forest'\n",
    "model_name = 'decision_tree'\n",
    "\n",
    "model = models[model_name]['model']\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "z = confusion_matrix(y_test, y_pred)\n",
    "y = ['False', 'True']\n",
    "x = ['False', 'True']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# change each element of z to type string for annotations\n",
    "z_text = [[str(y) for y in x] for x in z]\n",
    "\n",
    "# set up figure \n",
    "fig = ff.create_annotated_heatmap(z, x=x, y=y, annotation_text=z_text)\n",
    "\n",
    "# add title\n",
    "fig.update_layout(title_text='Confusion matrix: ' + model_name,\n",
    "                 )\n",
    "\n",
    "# add custom xaxis title\n",
    "fig.add_annotation(dict(font=dict(color=\"black\",size=14),\n",
    "                        x=0.5,\n",
    "                        y=-0.15,\n",
    "                        showarrow=False,\n",
    "                        text=\"Predicted value\",\n",
    "                        xref=\"paper\",\n",
    "                        yref=\"paper\"))\n",
    "\n",
    "# add custom yaxis title\n",
    "fig.add_annotation(dict(font=dict(color=\"black\",size=14),\n",
    "                        x=-0.35,\n",
    "                        y=0.5,\n",
    "                        showarrow=False,\n",
    "                        text=\"Real value\",\n",
    "                        textangle=-90,\n",
    "                        xref=\"paper\",\n",
    "                        yref=\"paper\"))\n",
    "\n",
    "# adjust margins to make room for yaxis title\n",
    "fig.update_layout(margin=dict(t=50, l=20))\n",
    "\n",
    "# add colorbar\n",
    "fig['data'][0]['showscale'] = True\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Decision tree visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def GetDecisionTreeGraphViz(dt):\n",
    "  return graphviz.Source(sklearn.tree.export_graphviz(\n",
    "      dt, out_file=None, filled=True, impurity=False,\n",
    "      feature_names=features))\n",
    "# The default visualization\n",
    "# display(GetDecisionTreeGraphViz(dt_fit))\n",
    "\n",
    "# The zoomed-out visualization\n",
    "display(Image(GetDecisionTreeGraphViz(dtm).pipe(format='png'), width=1024))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### ROC Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig = go.Figure()\n",
    "\n",
    "fig.add_shape(\n",
    "    type='line', line=dict(dash='dash'),\n",
    "    x0=0, x1=1, y0=0, y1=1\n",
    ")\n",
    "\n",
    "    \n",
    "for model_name in models:\n",
    "    \n",
    "    model = models[model_name]['model']\n",
    "    y_score = model.predict_proba(X_test)[:, 1]\n",
    "    fpr, tpr, thresholds = roc_curve(y_test, y_score)\n",
    "    auc_score = roc_auc_score(y_test, y_score)\n",
    "    \n",
    "    name = f\"{model_name} (AUC={auc_score:.2f})\"\n",
    "\n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=fpr, \n",
    "            y=tpr, \n",
    "            name=name, \n",
    "            mode='lines'\n",
    "        )\n",
    "    )\n",
    "\n",
    "fig.update_layout(\n",
    "    title='ROC Curves',\n",
    "    xaxis_title='False Positive Rate',\n",
    "    yaxis_title='True Positive Rate',\n",
    "    yaxis=dict(scaleanchor=\"x\", scaleratio=1),\n",
    "    xaxis=dict(constrain='domain'),\n",
    "    width=700, height=500\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sZrDaY0T5uLu",
    "tags": []
   },
   "source": [
    "# *Additional notes*"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  },
  "toc-autonumbering": true
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
