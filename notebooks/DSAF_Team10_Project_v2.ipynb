{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ytbjNyfmew7l"
   },
   "source": [
    "# **Predicting Bank Failures Using Machine Learning**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PijJ4Ptzez9Q"
   },
   "source": [
    "***Model Development and Operational Details***\n",
    "\n",
    "In this workbook, we perform in depth exploratory data analysis, data wrangling, and finally apply a logistic regression analysis to categorize banks as risky or healthy, in line with the FDIC's collected data. As discussed above, we use the Homeland Infrastructure Foundation's 2016 FDIC Insured Banks Data Set.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-YCndrOmspsv"
   },
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-YCndrOmspsv"
   },
   "source": [
    "#### Local imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-26T16:16:36.706123Z",
     "iopub.status.busy": "2023-04-26T16:16:36.705651Z",
     "iopub.status.idle": "2023-04-26T16:16:36.716369Z",
     "shell.execute_reply": "2023-04-26T16:16:36.715502Z",
     "shell.execute_reply.started": "2023-04-26T16:16:36.706036Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-YCndrOmspsv"
   },
   "source": [
    "#### Third party imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-26T16:33:57.892264Z",
     "iopub.status.busy": "2023-04-26T16:33:57.888727Z",
     "iopub.status.idle": "2023-04-26T16:33:58.117098Z",
     "shell.execute_reply": "2023-04-26T16:33:58.115440Z",
     "shell.execute_reply.started": "2023-04-26T16:33:57.892172Z"
    },
    "id": "KpwjUM-YeFDr",
    "tags": []
   },
   "outputs": [],
   "source": [
    "##Install Packages\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.max_rows', 10)\n",
    "import numpy as np\n",
    "import sklearn.tree\n",
    "import sklearn.metrics\n",
    "import sklearn.model_selection\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import roc_curve, roc_auc_score, auc, confusion_matrix\n",
    "import graphviz\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "from IPython.display import Image\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import plotly.figure_factory as ff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-YCndrOmspsv"
   },
   "source": [
    "#### Local application imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-26T16:35:36.153843Z",
     "iopub.status.busy": "2023-04-26T16:35:36.153090Z",
     "iopub.status.idle": "2023-04-26T16:35:36.228252Z",
     "shell.execute_reply": "2023-04-26T16:35:36.227370Z",
     "shell.execute_reply.started": "2023-04-26T16:35:36.153808Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from pkg_dir.config import *\n",
    "from pkg_dir.src.utils import *\n",
    "from pkg_dir.src.functions import *\n",
    "from pkg_dir.src.parameters import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FoALFdHYwgdl"
   },
   "source": [
    "# Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-26T16:35:36.660221Z",
     "iopub.status.busy": "2023-04-26T16:35:36.659791Z",
     "iopub.status.idle": "2023-04-26T16:35:38.768524Z",
     "shell.execute_reply": "2023-04-26T16:35:38.766327Z",
     "shell.execute_reply.started": "2023-04-26T16:35:36.660187Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset already present locally... skipping download...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../pkg_dir/src/functions/pipeline/extract_funcs.py:102: DtypeWarning: Columns (12,13) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  dfx = pd.read_csv(os.path.join(dataset_local_files, file))\n"
     ]
    },
    {
     "ename": "UnboundLocalError",
     "evalue": "local variable 'data_prefix' referenced before assignment",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [13]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mextract_pipeline_func\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/educacion/maestria/berkeley_mba_meng/academics/2023_spring/data_science_applied_to_finance_and_accounting/UCB_gclass_ds_for_finance_and_accounting/pkg_dir/src/functions/pipeline/extract_funcs.py:158\u001b[0m, in \u001b[0;36mextract_pipeline_func\u001b[0;34m()\u001b[0m\n\u001b[1;32m    155\u001b[0m     download_data_if_none()\n\u001b[1;32m    157\u001b[0m     \u001b[38;5;66;03m## Saving locally train and test dataset as df-pickle\u001b[39;00m\n\u001b[0;32m--> 158\u001b[0m     \u001b[43msave_extract_local_df_pkl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    160\u001b[0m     \u001b[38;5;66;03m## Saving local extract pickles in AWS S3\u001b[39;00m\n\u001b[1;32m    161\u001b[0m \u001b[38;5;66;03m#    save_extract_pkl_s3()\u001b[39;00m\n\u001b[1;32m    164\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/educacion/maestria/berkeley_mba_meng/academics/2023_spring/data_science_applied_to_finance_and_accounting/UCB_gclass_ds_for_finance_and_accounting/pkg_dir/src/functions/pipeline/extract_funcs.py:108\u001b[0m, in \u001b[0;36msave_extract_local_df_pkl\u001b[0;34m()\u001b[0m\n\u001b[1;32m    102\u001b[0m         dfx \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(dataset_local_files, file))\n\u001b[1;32m    104\u001b[0m         \u001b[38;5;66;03m## Saving df as pickle and storing it locally\u001b[39;00m\n\u001b[1;32m    105\u001b[0m         pickle\u001b[38;5;241m.\u001b[39mdump(\n\u001b[1;32m    106\u001b[0m             dfx,\n\u001b[1;32m    107\u001b[0m             \u001b[38;5;28mopen\u001b[39m(\n\u001b[0;32m--> 108\u001b[0m                 os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(pipeline_pkl_extract_local_dir) \u001b[38;5;241m+\u001b[39m \u001b[43mdata_prefix\u001b[49m \u001b[38;5;241m+\u001b[39m file\u001b[38;5;241m.\u001b[39msplit(sep\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m'\u001b[39m)[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.pkl\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m    109\u001b[0m                 \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwb\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    110\u001b[0m             )\n\u001b[1;32m    111\u001b[0m         )\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m\n",
      "\u001b[0;31mUnboundLocalError\u001b[0m: local variable 'data_prefix' referenced before assignment"
     ]
    }
   ],
   "source": [
    "extract_pipeline_func()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0swVsM2B5gEo",
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Data exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K_M3CGoN5gCA",
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### `SCORE_T`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "px.histogram(\n",
    "    x=dfk['SCORE'],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K_M3CGoN5gCA"
   },
   "source": [
    "# Data wrangling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_pipeline_func()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dvbZzH2EzZFD"
   },
   "source": [
    "### Setting index field as dataframe index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "moJoigxwziFp",
    "tags": []
   },
   "outputs": [],
   "source": [
    "dfk.set_index('index', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K_M3CGoN5gCA",
    "tags": []
   },
   "source": [
    "### Target variable - label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 300
    },
    "id": "3HskvuqdA3Tx",
    "outputId": "7a63b4ad-97e4-4aa8-9ae6-a5b3b57c9ae5",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# risk score, I think the thing we can try to predict. normally 100, sometimes less. \n",
    "# transformed SCORE to make a binary categorical thing for prediction\n",
    "# Right now since most of the data has a risk score of 100, I've made that the\n",
    "# cutoff, to get more representation for anything with a lower risk score.\n",
    "# We can adjust the cutoff though and be more permissive, depending on how\n",
    "# results look! \n",
    "dfk['SCORE_T'] = (dfk['SCORE'] < 100)*1\n",
    "target = ['SCORE_T']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K_M3CGoN5gCA",
    "tags": []
   },
   "source": [
    "### Adding relevant variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfk['DEP_RATIOS'] = dfk['DEPSUMBR']/dfk['DEPDOM']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l27qWIYj5f_J"
   },
   "source": [
    "# Feature engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K_M3CGoN5gCA",
    "tags": []
   },
   "source": [
    "### Categorical features transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 300
    },
    "id": "3HskvuqdA3Tx",
    "outputId": "7a63b4ad-97e4-4aa8-9ae6-a5b3b57c9ae5",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Data transformation to use following\n",
    "# categorical features that may need transformation:\n",
    "    # - bank classification - 1-2 letters string categorization\n",
    "    # 'BKCLASS',\n",
    "    # - regulatory agent. surprised it's not always \"FDIC\" - various strings. could convert category to # if need be. \n",
    "    # 'REGAGNT',\n",
    "    # - status. string, single letter. don't know values. \n",
    "    # 'STATUS',\n",
    "dfk['BKCLASS_T'] = dfk['BKCLASS'].astype('category').cat.codes\n",
    "dfk['REGAGNT_T'] = dfk['REGAGNT'].astype('category').cat.codes\n",
    "dfk['STATUS_T'] = dfk['STATUS'].astype('category').cat.codes\n",
    "dfk['DEP_RATIO'] = dfk['DEPSUMBR']/dfk['DEPDOM']\n",
    "dfk['DEP_RATIO'][dfk['DEPDOM']==0] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K_M3CGoN5gCA",
    "tags": []
   },
   "source": [
    "### Features definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 300
    },
    "id": "3HskvuqdA3Tx",
    "outputId": "7a63b4ad-97e4-4aa8-9ae6-a5b3b57c9ae5",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# - denovo or not - all 0, not useful!\n",
    "# report date is all June 30 2014\n",
    "features = [\n",
    "    # possible labels incl:\n",
    "    # - bank number\n",
    "    'BRNUM',\n",
    "    # - unique id for bank\n",
    "    'UNINUMBR',\n",
    "\n",
    "    # geography that may need larger dimension to be useful:\n",
    "    # - statistical geo area code, but numerical\n",
    "    'CBSABR',\n",
    "    # - zip code bank\n",
    "    'ZIPBR',\n",
    "\n",
    "    # actual trainable features\n",
    "    # - total deposit $ <- this actually means Branch\n",
    "    'DEPSUMBR',\n",
    "    # - asset size bank\n",
    "    'ASSET',\n",
    "    # - domestic deposits $. <- this actually means Institution\n",
    "    'DEPDOM',\n",
    "    # $ branch/ $ institution\n",
    "    'DEP_RATIO',\n",
    "    # incl. categorical features that got transformed:\n",
    "    # - bank classification - 1-2 letters string categorization\n",
    "    'BKCLASS_T',\n",
    "    # - regulatory agent. surprised it's not always \"FDIC\" - various strings. \n",
    "    'REGAGNT_T',\n",
    "    # - status. string, single letter. don't know values. \n",
    "    'STATUS_T',\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dfk = dfk[features + target].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 300
    },
    "id": "3HskvuqdA3Tx",
    "outputId": "7a63b4ad-97e4-4aa8-9ae6-a5b3b57c9ae5",
    "tags": []
   },
   "outputs": [],
   "source": [
    "dfk[features].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wMFELCj7QtLh",
    "outputId": "bcc3b322-13d0-4c89-f51e-52510b877a79",
    "tags": []
   },
   "outputs": [],
   "source": [
    "dfk[target].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_ie0n9lx5ezm"
   },
   "source": [
    "# Building model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BEMI3tCqzZCQ"
   },
   "source": [
    "### Splitting data in test and train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Qrh7A90czj1r",
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    dfk.loc[:, dfk.columns != 'SCORE_T'],\n",
    "    dfk['SCORE_T'], \n",
    "    test_size=data_test_size,\n",
    "    random_state=random_state\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BEMI3tCqzZCQ"
   },
   "source": [
    "### Logistic regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "lrm = LogisticRegression(\n",
    "    random_state=random_state,\n",
    "    max_iter=1000,\n",
    ").fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BEMI3tCqzZCQ"
   },
   "source": [
    "### Random forest model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc = RandomForestClassifier(\n",
    "    random_state=random_state,\n",
    "    max_depth=100\n",
    ").fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BEMI3tCqzZCQ",
    "tags": []
   },
   "source": [
    "### Decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AWgseDaaP9dE",
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# lowered max depth so it would run\n",
    "dtm = sklearn.tree.DecisionTreeClassifier(\n",
    "    max_depth=2, \n",
    "    random_state=random_state,\n",
    ").fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BEMI3tCqzZCQ"
   },
   "source": [
    "### Models compilation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "models = {\n",
    "    'logistic_reg': {\n",
    "        'model': lrm,\n",
    "    },\n",
    "    'random_forest': {\n",
    "        'model': rfc,\n",
    "    },\n",
    "    'decision_tree': {\n",
    "        'model': dtm,\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SpuNAOcw5rqi"
   },
   "source": [
    "# Evaluating models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### General model metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dfx = pd.DataFrame(\n",
    "    # columns=['Logistic Regression', 'Decision Tree', 'Random Forest'],\n",
    "    index=[\n",
    "        'Training performance',\n",
    "        'Test performance',\n",
    "        'Training sensitivity',\n",
    "        'Training specificity',\n",
    "        'Test sensitivity',\n",
    "        'Test specificity',\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# model_name = 'logistic_reg'\n",
    "# model_name = 'random_forest'\n",
    "model_name = 'decision_tree'\n",
    "\n",
    "model = models[model_name]['model']\n",
    "\n",
    "predicted_train = model.predict(X_train)\n",
    "predicted_test = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cm_train = sklearn.metrics.confusion_matrix(y_train, predicted_train)\n",
    "cm_test = sklearn.metrics.confusion_matrix(y_test, predicted_test)\n",
    "\n",
    "def SensitivityAndSpecificity(cm):\n",
    "  # True positives are in the lower-right (row 1, column 1)\n",
    "  TP = cm[1, 1]\n",
    "  # True negatives are in the upper-left (row 0, column 0)\n",
    "  TN = cm[0, 0]\n",
    "  # False positives are in the upper-right (row 0, columns 1)\n",
    "  FP = cm[0, 1]\n",
    "  # False negatives are in the lower-left (row 1, column 0)\n",
    "  FN = cm[1, 0]\n",
    "  sensitivity = TP / (TP + FN)\n",
    "  specificity = TN / (TN + FP)\n",
    "  return {'Sensitivity': sensitivity, 'Specificity': specificity}\n",
    "\n",
    "dfx.loc['Training performance', model_name] = np.mean(predicted_train == y_train)\n",
    "dfx.loc['Test performance', model_name] = np.mean(predicted_test == y_test)\n",
    "dfx.loc['Training sensitivity', model_name] = SensitivityAndSpecificity(cm_train)['Sensitivity']\n",
    "dfx.loc['Training specificity', model_name] = SensitivityAndSpecificity(cm_train)['Specificity']\n",
    "dfx.loc['Test sensitivity', model_name] = SensitivityAndSpecificity(cm_test)['Sensitivity']\n",
    "dfx.loc['Test specificity', model_name] = SensitivityAndSpecificity(cm_test)['Specificity']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### CART regression feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=[12, 4])\n",
    "I = np.argsort(dtm.feature_importances_)\n",
    "plt.figure(figsize=[12, 4])\n",
    "plt.bar([features[i] for i in I], [dtm.feature_importances_[i] for i in I])\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# model_name = 'logistic_reg'\n",
    "# model_name = 'random_forest'\n",
    "model_name = 'decision_tree'\n",
    "\n",
    "model = models[model_name]['model']\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "z = confusion_matrix(y_test, y_pred)\n",
    "y = ['False', 'True']\n",
    "x = ['False', 'True']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# change each element of z to type string for annotations\n",
    "z_text = [[str(y) for y in x] for x in z]\n",
    "\n",
    "# set up figure \n",
    "fig = ff.create_annotated_heatmap(z, x=x, y=y, annotation_text=z_text)\n",
    "\n",
    "# add title\n",
    "fig.update_layout(title_text='Confusion matrix: ' + model_name,\n",
    "                 )\n",
    "\n",
    "# add custom xaxis title\n",
    "fig.add_annotation(dict(font=dict(color=\"black\",size=14),\n",
    "                        x=0.5,\n",
    "                        y=-0.15,\n",
    "                        showarrow=False,\n",
    "                        text=\"Predicted value\",\n",
    "                        xref=\"paper\",\n",
    "                        yref=\"paper\"))\n",
    "\n",
    "# add custom yaxis title\n",
    "fig.add_annotation(dict(font=dict(color=\"black\",size=14),\n",
    "                        x=-0.35,\n",
    "                        y=0.5,\n",
    "                        showarrow=False,\n",
    "                        text=\"Real value\",\n",
    "                        textangle=-90,\n",
    "                        xref=\"paper\",\n",
    "                        yref=\"paper\"))\n",
    "\n",
    "# adjust margins to make room for yaxis title\n",
    "fig.update_layout(margin=dict(t=50, l=20))\n",
    "\n",
    "# add colorbar\n",
    "fig['data'][0]['showscale'] = True\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Decision tree visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def GetDecisionTreeGraphViz(dt):\n",
    "  return graphviz.Source(sklearn.tree.export_graphviz(\n",
    "      dt, out_file=None, filled=True, impurity=False,\n",
    "      feature_names=features))\n",
    "# The default visualization\n",
    "# display(GetDecisionTreeGraphViz(dt_fit))\n",
    "\n",
    "# The zoomed-out visualization\n",
    "display(Image(GetDecisionTreeGraphViz(dtm).pipe(format='png'), width=1024))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### ROC Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig = go.Figure()\n",
    "\n",
    "fig.add_shape(\n",
    "    type='line', line=dict(dash='dash'),\n",
    "    x0=0, x1=1, y0=0, y1=1\n",
    ")\n",
    "\n",
    "    \n",
    "for model_name in models:\n",
    "    \n",
    "    model = models[model_name]['model']\n",
    "    y_score = model.predict_proba(X_test)[:, 1]\n",
    "    fpr, tpr, thresholds = roc_curve(y_test, y_score)\n",
    "    auc_score = roc_auc_score(y_test, y_score)\n",
    "    \n",
    "    name = f\"{model_name} (AUC={auc_score:.2f})\"\n",
    "\n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=fpr, \n",
    "            y=tpr, \n",
    "            name=name, \n",
    "            mode='lines'\n",
    "        )\n",
    "    )\n",
    "\n",
    "fig.update_layout(\n",
    "    title='ROC Curves',\n",
    "    xaxis_title='False Positive Rate',\n",
    "    yaxis_title='True Positive Rate',\n",
    "    yaxis=dict(scaleanchor=\"x\", scaleratio=1),\n",
    "    xaxis=dict(constrain='domain'),\n",
    "    width=700, height=500\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sZrDaY0T5uLu",
    "tags": []
   },
   "source": [
    "# *Additional notes*"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  },
  "toc-autonumbering": true
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
